{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ab2650-4708-432b-805b-73bce4012c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in c:\\anaconda\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\anaconda\\lib\\site-packages (from Flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\anaconda\\lib\\site-packages (from Flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\anaconda\\lib\\site-packages (from Flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\anaconda\\lib\\site-packages (from Flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\anaconda\\lib\\site-packages (from Flask) (1.6.2)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from click>=8.1.3->Flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\lib\\site-packages (from Jinja2>=3.1.2->Flask) (2.1.3)\n",
      "Requirement already satisfied: gensim in c:\\anaconda\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\anaconda\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\anaconda\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\anaconda\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\anaconda\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\anaconda\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests) (2024.7.4)\n",
      "Requirement already satisfied: nltk in c:\\anaconda\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\anaconda\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\anaconda\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\anaconda\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\anaconda\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Requirement already satisfied: torch in c:\\anaconda\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\anaconda\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\anaconda\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\anaconda\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\anaconda\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: transformers in c:\\anaconda\\lib\\site-packages (4.44.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda\\lib\\site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\anaconda\\lib\\site-packages (from transformers) (0.24.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\anaconda\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\anaconda\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\anaconda\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\anaconda\\lib\\site-packages (from transformers) (0.4.4)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\anaconda\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\anaconda\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\anaconda\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: Werkzeug in c:\\anaconda\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\anaconda\\lib\\site-packages (from Werkzeug) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install Flask\n",
    "!pip install gensim\n",
    "!pip install beautifulsoup4\n",
    "!pip install requests\n",
    "!pip install nltk\n",
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install scikit-learn\n",
    "!pip install Werkzeug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cb709d-ad2d-4549-91c1-11ef01967137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template, jsonify\n",
    "from gensim import corpora\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import BertTokenizer, BertModel, pipeline\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import traceback\n",
    "from werkzeug.serving import run_simple\n",
    "\n",
    "app = Flask(__name__, template_folder='my_templates')\n",
    "app.config['TEMPLATES_AUTO_RELOAD'] = True\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def extract_patent_claims(url):\n",
    "    pages = requests.get(url)\n",
    "    soup = BeautifulSoup(pages.text, 'html.parser')\n",
    "    claims = soup.find_all('div', class_='claim-text')\n",
    "    return [claim.get_text(strip=True) for claim in claims]\n",
    "\n",
    "def preprocess_claims(claims):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_claims = []\n",
    "    for claim in claims:\n",
    "        claim = claim.lower()\n",
    "        claim = re.sub(r'[^a-z\\s]', '', claim)\n",
    "        tokens = word_tokenize(claim)\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        processed_claims.append(' '.join(tokens))\n",
    "    return processed_claims\n",
    "\n",
    "def get_bert_embeddings(texts):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            embeddings.append(outputs.last_hidden_state[:, 0, :].squeeze().numpy())\n",
    "    return np.array(embeddings)\n",
    "\n",
    "def generate_topic_title(claims, summarizer):\n",
    "    combined_claims = ' '.join(claims)\n",
    "    words = combined_claims.split()\n",
    "    \n",
    "    if len(words) > 512:\n",
    "        chunk_size = 256\n",
    "        summaries = []\n",
    "        for i in range(0, len(words), chunk_size):\n",
    "            chunk = ' '.join(words[i:i+chunk_size])\n",
    "            summary = summarizer(chunk, max_length=20, min_length=5, do_sample=False)\n",
    "            summaries.append(summary[0]['summary_text'])\n",
    "        \n",
    "        combined_summary = ' '.join(summaries)\n",
    "        final_summary = summarizer(combined_summary, max_length=20, min_length=5, do_sample=False)\n",
    "        return final_summary[0]['summary_text']\n",
    "    else:\n",
    "        summary = summarizer(combined_claims, max_length=20, min_length=5, do_sample=False)\n",
    "        return summary[0]['summary_text']\n",
    "\n",
    "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
    "def index():\n",
    "    if request.method == \"POST\":\n",
    "        try:\n",
    "            num_clusters = int(request.form['num_clusters'])\n",
    "            list_url = [\n",
    "                'https://patents.google.com/patent/US9634864B2/en?oq=US9634864B2',\n",
    "                'https://patents.google.com/patent/US9980046B2/en?oq=US9980046B2',\n",
    "                'https://patents.google.com/patent/GB2478972A/en?q=(phone)&oq=phone']\n",
    "            \n",
    "            claims = []\n",
    "            for url in list_url:\n",
    "                claims.extend(extract_patent_claims(url))\n",
    "\n",
    "            preprocessed_claims = preprocess_claims(claims)\n",
    "            embeddings = get_bert_embeddings(preprocessed_claims)\n",
    "            \n",
    "            cluster = AgglomerativeClustering(n_clusters=num_clusters, metric='euclidean', linkage='ward')\n",
    "            cluster_labels = cluster.fit_predict(embeddings)\n",
    "            \n",
    "            grouped_claims = {i: [] for i in range(num_clusters)}\n",
    "            for idx, label in enumerate(cluster_labels):\n",
    "                grouped_claims[label].append(preprocessed_claims[idx])\n",
    "\n",
    "            summarizer = pipeline('summarization', model=\"facebook/bart-large-cnn\")\n",
    "            group_titles = {group: generate_topic_title(claims, summarizer) for group, claims in grouped_claims.items()}\n",
    "            \n",
    "            response = {\n",
    "                'groups': [\n",
    "                    {\n",
    "                        'title': group_titles[group],\n",
    "                        'number_of_claims': len(claims)\n",
    "                    }\n",
    "                    for group, claims in grouped_claims.items()]}\n",
    "            \n",
    "            return render_template(\"results.html\", num_clusters=num_clusters, groups=response['groups'])\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            return \"An error occurred, please check the console for details.\", 500\n",
    "    else:\n",
    "        return render_template(\"index.html\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
